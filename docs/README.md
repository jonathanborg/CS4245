<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
# Animated Face Creation using Generative Adversarial Networks

## A Computer Vision by Deep Learning Study

<u>Group 24</u> -  **Frans de Boer**, **Jonathan Borg**, **Haoran Xia**

Original Paper: [https://arxiv.org/abs/1708.05509](https://arxiv.org/abs/1708.05509)


[//]: # "Differences:"
[//]: # "Images are set to a resolution of 96x96 - theirs was 128x128"

---

## Introduction

Generative adversarial networks (GAN) are composed of two primary components, the generator, a neural network tasked with generating images appearing to be as 'real' as possible, and the discriminator, another neural network charged with determining if the supplied image is real or fake (i.e., generated by the other network). These two networks compete against each other to form a [zero-sum game](https://en.wikipedia.org/wiki/Zero-sum_game), where one agent's gain is another agent's loss.

Following the advancements of GANs in several fields, we decided to implement a model capable of generating animated faces. Even though such research is not new, as shown by Y. Jin\cite{jin2017towards}, we believe that different model architectures can yield stronger results.

Apart from the model generation, ample tests, such as different model architectures and different datasets with diverse animation styles, were carried out to develop a robust and stable model. This allowed us to compare how our model would scale against other research, such as the benchmark model supplied by Y. Zheng\cite{zheng2020cartoon}.

Therefore, we set out to create a GAN capable of generating animated faces based on the data set provided during training (usually specific to a particular style of drawing - cartoon or anime). In the following sections, we illustrate and explain how this was set up, the architectures used, and different data suppliedâ€”followed by all the experiments carried out to evaluate and compare our model.

---

## Technical details & Background
[//]: # "Maybe a section about convolutions? -Would it be needed for our research?"

### GANs
Our implemented models are all based on the GAN\cite{goodfellow2014generative} architecture. GANs are types of frameworks used for learning the training data's distribution such that new data can be generated from learned distribution. 

A GAN consists of two key components, a **generator** and a **discriminator**. The generator is tasked with generating 'fake' data (images) that look similar to the real (training) images, while the discriminator tries to classify an image as either real or fake (generated). 
These two components are trained in an adversarial way such that the generator tries to 'outsmart' the discriminator by generating more realistic 'fake' images, while the discriminator tries to better classify whether its given input is real or fake. 

This adversarial way of training continues until an equilibrium is achieved where the generator can create perfect fakes. That is, the discriminator can only guess whether some input is real or fake (50% confidence in its classifications). 
 

###GAN Training 
As previously mentioned, the generator and discriminator are trained jointly within a GAN. The loss function is as follows:

![GAN Loss](Images/gan_loss.PNG)

Where $(D(x))$ is the discriminator, and $(G(x))$ is the generator. $(D(G(x)))$ is the probability that the output of generator $(G())$ is a real image. 

The discriminator and the generator play a minimax game where the discriminator tries to maximize the probability of classifying real and fake images correctly. In contrast, the generator minimizes the likelihood that the discriminator classifies the generated data as fake. 



### Network architecture


---

## Method & Approach

### Model

### Datasets

### Parameters


### Training

---

## Experiments & Results



### Architecture Change


### Data Set Selection


### Epoch Selection

#### Testing curve results

---

## Discussion




---

## Future Work


## Conclusion


---

## References

[1] Jin, Y., Zhang, J., Li, M., Tian, Y., Zhu, H., & Fang, Z. (2017). Towards the automatic anime characters creation with generative adversarial networks. arXiv preprint arXiv:1708.05509.
