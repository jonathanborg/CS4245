{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Package Setup and Initialization\nImport all required libraries","metadata":{}},{"cell_type":"code","source":"import torch as th\nimport torchvision\nfrom torch.utils.data import DataLoader\n\nimport os\nimport matplotlib.pyplot as plt\nimport torchvision.utils as vutils\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup configuration\nSetup hyperparameters for the network to use","metadata":{}},{"cell_type":"code","source":"# Network\nNOISE_SIZE = 100\nNOISE_TYPE = 'normal' \nCRITIC_FEATURE_MAP_DEPTH = 64               # in WGAN the Discriminator is called the Critic\nGENERATOR_FEATURE_MAP_DEPTH = 64\n\n# Training \nSAVE_CHECKPOINT_EVERY = 10 \nSAVE_IMAGE_EVERY = 10\nBATCH_SIZE = 64\nEPOCHS = 100\nDISCRIMINATOR_LR = 5e-5\nGENERATOR_LR = 5e-5 \nTRUE_LABEL_VALUE = 1\nFAKE_LABEL_VALUE = 0\n\n# WGAN params\nNUM_EPOCHS = 5\nCRITIC_ITERATIONS = 5\nWEIGHT_CLIP = 0.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup device and data","metadata":{}},{"cell_type":"code","source":"# Device\ndevice = th.device('cuda' if th.cuda.is_available() else 'cpu')\n\n# Dataset\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n])\n\ndata_directory = \"/kaggle/input/\"\ndataset = torchvision.datasets.ImageFolder(data_directory, transform=transform)\n\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Network\nCritic (Discriminator) and Generator\nNote that the Critic in WGAN doest not have a sigmoid activation function in its last layer as opposed to the DCGAN variant. ","metadata":{}},{"cell_type":"code","source":"# DISCRIMINATOR\nclass CriticBlock(th.nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, first: bool = False, last: bool = False) -> None:\n        assert(not (first and last)) # block can't be both first and last\n        super().__init__()\n        if first:\n            self.main = th.nn.Sequential(\n                th.nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False),\n                th.nn.LeakyReLU(0.2, inplace=True),\n            )\n            \n        elif last:\n            self.main = th.nn.Sequential(\n                th.nn.Conv2d(in_channels, out_channels, 3, 1, 0, bias=False),\n                # No Sigmoid activation in WGAN in last layer\n            )\n\n        else:\n            self.main = th.nn.Sequential(\n                th.nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False),\n                th.nn.BatchNorm2d(out_channels),\n                th.nn.LeakyReLU(0.2, inplace=True),\n            )\n\n    def forward(self, x: th.Tensor) -> th.Tensor:\n        return self.main(x)\n\nclass Critic(th.nn.Module):\n    def __init__(self, feature_map_depth: int) -> None:\n        super().__init__()\n        self.main = th.nn.Sequential(\n            CriticBlock(3, feature_map_depth, first=True),\n            CriticBlock(feature_map_depth, feature_map_depth * 2),\n            CriticBlock(feature_map_depth * 2, feature_map_depth * 4),\n            CriticBlock(feature_map_depth * 4, feature_map_depth * 8),\n            CriticBlock(feature_map_depth * 8, feature_map_depth * 8),\n            CriticBlock(feature_map_depth * 8, 1, last=True)\n        )\n\n    def forward(self, x: th.Tensor) -> th.Tensor:\n        x = self.main(x)\n        return x\n\n\n\n# GENERATOR\nclass GeneratorBlock(th.nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, first: bool = False, last: bool = False) -> None:\n        assert(not (first and last)) # block can't be both first and last\n        super().__init__()\n        if first:\n            self.main = th.nn.Sequential(\n                th.nn.ConvTranspose2d(in_channels, out_channels, 3, 1, 0, bias=False),\n                th.nn.BatchNorm2d(out_channels),\n                th.nn.ReLU(True)\n            )\n        elif last:\n            self.main = th.nn.Sequential(\n                th.nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n                th.nn.Tanh()\n            )\n        else:\n            self.main = th.nn.Sequential(\n                th.nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n                th.nn.BatchNorm2d(out_channels),\n                th.nn.ReLU(True)\n            )\n\n    def forward(self, x: th.Tensor) -> th.Tensor:\n        return self.main(x)\n\nclass Generator(th.nn.Module):\n    def __init__(self, noise_size: int, feature_map_depth: int) -> None:\n        super().__init__()\n        # first layer, no stride. Upsample from 1x1 to 4x4\n        self.main = th.nn.Sequential(\n            GeneratorBlock(noise_size, feature_map_depth * 8, first=True),\n            GeneratorBlock(feature_map_depth * 8, feature_map_depth * 8),\n            GeneratorBlock(feature_map_depth * 8, feature_map_depth * 4),\n            GeneratorBlock(feature_map_depth * 4, feature_map_depth * 2),\n            GeneratorBlock(feature_map_depth * 2, feature_map_depth * 1),\n            GeneratorBlock(feature_map_depth * 1, 3, last=True),\n        )\n\n    def forward(self, x: th.Tensor) -> th.Tensor:\n        x = self.main(x)\n        return x\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimizer and creating network","metadata":{}},{"cell_type":"code","source":"# Initialize weights\ndef weights_init(model):\n    classname = model.__class__.__name__\n    if classname.find('Conv') != -1:\n        th.nn.init.normal_(model.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        th.nn.init.normal_(model.weight.data, 1.0, 0.02)\n        th.nn.init.constant_(model.bias.data, 0)\n\n\n# Create network\ngenerator = Generator(NOISE_SIZE, GENERATOR_FEATURE_MAP_DEPTH).to(device)\ngenerator.apply(weights_init)\n\ncritic = Critic(CRITIC_FEATURE_MAP_DEPTH).to(device)\ncritic.apply(weights_init)\n\n# Optimizer\ncritic_optimizer = th.optim.RMSprop(critic.parameters(), lr=DISCRIMINATOR_LR)\ngenerator_optimizer = th.optim.RMSprop(generator.parameters(), lr=GENERATOR_LR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utility functions","metadata":{}},{"cell_type":"code","source":"# Constants\n# results_path = \"kaggle\"\n# experiment_name = \"working\"\nFULL_PATH = f'output'\nfixed_noise = th.randn(64, NOISE_SIZE, 1, 1, device=device)\n\n# Create output folder if it doesn't exist yet\nif not os.path.isdir('output'): \n    os.mkdir('output')\n\n# Utility functions\ndef save_model_checkpoint(epoch: int) -> None:\n    make_epoch_directories(epoch)\n    checkpoint_path = f'{FULL_PATH}/{epoch}'\n    th.save({\n        'epoch': epoch,\n        'generator_model_state_dict': generator.state_dict(),\n        'discriminator_model_state_dict': critic.state_dict(),\n        'generator_optimizer_state_dict': generator_optimizer.state_dict(),\n        'discriminator_optimizer_state_dict': critic_optimizer.state_dict(),\n    }, f'{checkpoint_path}/checkpoint.th')\n\n\ndef make_epoch_directories(epoch: int) -> None:\n    epoch_path = f'{FULL_PATH}/{epoch}'\n    if not os.path.isdir(epoch_path):\n        os.mkdir(epoch_path)\n\n\ndef save_model_image(epoch: int) -> None:\n    make_epoch_directories(epoch)\n    image_path = f'{FULL_PATH}/{epoch}/images'\n    if not os.path.isdir(image_path):\n        os.mkdir(image_path)\n    random_noise = th.randn(64, NOISE_SIZE, 1, 1, device=device)\n    fixed_fakes = generator(fixed_noise).detach().cpu()\n    random_fakes = generator(random_noise).detach().cpu()\n    save_image_grid(fixed_fakes, f'{image_path}/fixed.png', 'Fixed Noise')\n    save_image_grid(random_fakes, f'{image_path}/random.png', 'Random Noise')\n\n\ndef save_image_grid(images, path: str, title: str) -> None:\n    plt.figure(figsize=(8,8))\n    plt.axis('off')\n    plt.title(title)\n    plt.imshow(np.transpose(vutils.make_grid(images.to(device)[:64], padding=2, normalize=True).cpu(), (1, 2, 0)))\n    plt.savefig(path)\n    plt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training loop\nMain training loop. Note that we use the algorithm outlined in the WGAN paper. So in this case the Critic is updated more frequently (5x) and we use the Loss Function descrbied in the paper (and other resources online see: https://machinelearningmastery.com/how-to-implement-wasserstein-loss-for-generative-adversarial-networks/) \n\nFrom this blogpost:\n    Critic Loss = [average critic score on real images] â€“ [average critic score on fake images]\n    Generator Loss = -[average critic score on fake images]\n","metadata":{}},{"cell_type":"code","source":"Critic_losses = []\nGenerator_losses = []\n\nfor epoch in range(EPOCHS):\n    print('EPOCH: ', epoch)\n\n    for batch_idx, (real, _) in enumerate(dataloader):\n        real = real.to(device)\n        batch_size = real.size(0)\n        \n        # TRAIN DISCRIMINATOR (CRITIC) MORE. (5x according to paper)\n        for _ in range(CRITIC_ITERATIONS):\n            noise = th.randn(batch_size, NOISE_SIZE, 1, 1, device=device)\n            global fake \n            fake = generator(noise)\n            \n            discriminator_fake = critic(fake).reshape(-1)\n    \n            discriminator_real = critic(real).reshape(-1)\n            \n            # extra '-' because originally we want to maximize, so we minimize the negative.\n            loss_discriminator = -(th.mean(discriminator_fake) - th.mean(discriminator_real))\n            \n            critic.zero_grad()\n            loss_discriminator.backward(retain_graph=True)\n            critic_optimizer.step()\n\n            for p in critic.parameters():\n                p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)\n\n        # TRAIN GENERATOR \n        output = critic(fake).reshape(-1)\n        loss_generator = -th.mean(output)\n        generator.zero_grad() \n        loss_generator.backward()\n        generator_optimizer.step()\n\n        # Output training stats\n\n    # SAVE IMAGES\n    if epoch % SAVE_CHECKPOINT_EVERY == 0:\n        print('-> Saving model checkpoint')\n        save_model_checkpoint(epoch)\n    \n    if epoch % SAVE_IMAGE_EVERY == 0:\n        print('-> Saving model images')\n        save_model_image(epoch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}