{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Package Setup and Initialization\n","Import all required libraries"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["import torch as th\n","import torchvision\n","from torch.utils.data import DataLoader\n","\n","import os\n","import matplotlib.pyplot as plt\n","import torchvision.utils as vutils\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["# Setup configuration\n","Setup hyperparameters for the network to use"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["# Network\n","NOISE_SIZE = 100\n","NOISE_TYPE = 'normal' \n","CRITIC_FEATURE_MAP_DEPTH = 64               # in WGAN the Discriminator is called the Critic\n","GENERATOR_FEATURE_MAP_DEPTH = 64\n","\n","# Training \n","SAVE_CHECKPOINT_EVERY = 10 \n","SAVE_IMAGE_EVERY = 10\n","BATCH_SIZE = 64\n","EPOCHS = 200\n","DISCRIMINATOR_LR = 5e-5\n","GENERATOR_LR = 1e-5 \n","TRUE_LABEL_VALUE = 1\n","FAKE_LABEL_VALUE = 0\n","\n","# WGAN params\n","NUM_EPOCHS = 5\n","CRITIC_ITERATIONS = 5\n","# WEIGHT_CLIP = 0.1\n","\n","# WGAN-GP params\n","LAMBDA_GP = 10\n","\n","# Version nr\n","VERSION = 21"]},{"cell_type":"markdown","metadata":{},"source":["# Setup device and data"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on device: cuda\n"]}],"source":["# Device\n","device = th.device('cuda' if th.cuda.is_available() else 'cpu')\n","\n","print(\"Running on device:\", device)\n","\n","# Dataset\n","transform = torchvision.transforms.Compose([\n","    torchvision.transforms.ToTensor(),\n","])\n","\n","#data_directory = \"/kaggle/input/\"\n","data_directory = \"./data/faces/\"\n","dataset = torchvision.datasets.ImageFolder(data_directory, transform=transform)\n","\n","dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Network\n","Critic (Discriminator) and Generator\n","Note that the Critic in WGAN doest not have a sigmoid activation function in its last layer as opposed to the DCGAN variant. "]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["# DISCRIMINATOR\n","class CriticBlock(th.nn.Module):\n","    def __init__(self, in_channels: int, out_channels: int, first: bool = False, last: bool = False) -> None:\n","        assert(not (first and last)) # block can't be both first and last\n","        super().__init__()\n","        if first:\n","            self.main = th.nn.Sequential(\n","                th.nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False),\n","                th.nn.LeakyReLU(0.2, inplace=True),\n","            )\n","            \n","        elif last:\n","            self.main = th.nn.Sequential(\n","                th.nn.Conv2d(in_channels, out_channels, 3, 1, 0, bias=False),\n","                # No Sigmoid activation in WGAN in last layer\n","            )\n","\n","        else:\n","            self.main = th.nn.Sequential(\n","                th.nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False),\n","                th.nn.InstanceNorm2d(out_channels, affine=True), # WGAN-GP does not use BatchNorm for the Critic (LayerNorm or InstanceNorm)\n","                th.nn.LeakyReLU(0.2, inplace=True),\n","            )\n","\n","    def forward(self, x: th.Tensor) -> th.Tensor:\n","        return self.main(x)\n","\n","class Critic(th.nn.Module):\n","    def __init__(self, feature_map_depth: int) -> None:\n","        super().__init__()\n","        self.main = th.nn.Sequential(\n","            CriticBlock(3, feature_map_depth, first=True),\n","            CriticBlock(feature_map_depth, feature_map_depth * 2),\n","            CriticBlock(feature_map_depth * 2, feature_map_depth * 4),\n","            CriticBlock(feature_map_depth * 4, feature_map_depth * 8),\n","            CriticBlock(feature_map_depth * 8, feature_map_depth * 8),\n","            CriticBlock(feature_map_depth * 8, 1, last=True)\n","        )\n","\n","    def forward(self, x: th.Tensor) -> th.Tensor:\n","        x = self.main(x)\n","        return x\n","\n","\n","\n","# GENERATOR\n","class GeneratorBlock(th.nn.Module):\n","    def __init__(self, in_channels: int, out_channels: int, first: bool = False, last: bool = False) -> None:\n","        assert(not (first and last)) # block can't be both first and last\n","        super().__init__()\n","        if first:\n","            self.main = th.nn.Sequential(\n","                th.nn.ConvTranspose2d(in_channels, out_channels, 3, 1, 0, bias=False),\n","                th.nn.BatchNorm2d(out_channels),\n","                th.nn.ReLU(True)\n","            )\n","        elif last:\n","            self.main = th.nn.Sequential(\n","                th.nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n","                th.nn.Tanh()\n","            )\n","        else:\n","            self.main = th.nn.Sequential(\n","                th.nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n","                th.nn.BatchNorm2d(out_channels),\n","                th.nn.ReLU(True)\n","            )\n","\n","    def forward(self, x: th.Tensor) -> th.Tensor:\n","        return self.main(x)\n","\n","class Generator(th.nn.Module):\n","    def __init__(self, noise_size: int, feature_map_depth: int) -> None:\n","        super().__init__()\n","        # first layer, no stride. Upsample from 1x1 to 4x4\n","        self.main = th.nn.Sequential(\n","            GeneratorBlock(noise_size, feature_map_depth * 8, first=True),\n","            GeneratorBlock(feature_map_depth * 8, feature_map_depth * 8),\n","            GeneratorBlock(feature_map_depth * 8, feature_map_depth * 4),\n","            GeneratorBlock(feature_map_depth * 4, feature_map_depth * 2),\n","            GeneratorBlock(feature_map_depth * 2, feature_map_depth * 1),\n","            GeneratorBlock(feature_map_depth * 1, 3, last=True),\n","        )\n","\n","    def forward(self, x: th.Tensor) -> th.Tensor:\n","        x = self.main(x)\n","        return x\n"]},{"cell_type":"markdown","metadata":{},"source":["# Optimizer and creating network"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["Critic(\n","  (main): Sequential(\n","    (0): CriticBlock(\n","      (main): Sequential(\n","        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): CriticBlock(\n","      (main): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): CriticBlock(\n","      (main): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (3): CriticBlock(\n","      (main): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (4): CriticBlock(\n","      (main): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (5): CriticBlock(\n","      (main): Sequential(\n","        (0): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","      )\n","    )\n","  )\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize weights\n","def weights_init(model):\n","    classname = model.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        th.nn.init.normal_(model.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        th.nn.init.normal_(model.weight.data, 1.0, 0.02)\n","        th.nn.init.constant_(model.bias.data, 0)\n","\n","\n","# Create network\n","generator = Generator(NOISE_SIZE, GENERATOR_FEATURE_MAP_DEPTH).to(device)\n","generator.apply(weights_init)\n","\n","critic = Critic(CRITIC_FEATURE_MAP_DEPTH).to(device)\n","critic.apply(weights_init)\n","\n","# Optimizer (WGAN uses RMSprop, WGAN-GP uses Adam)\n","critic_optimizer = th.optim.RMSprop(critic.parameters(), lr=DISCRIMINATOR_LR)\n","generator_optimizer = th.optim.RMSprop(generator.parameters(), lr=GENERATOR_LR)\n","\n","generator.train()\n","critic.train()"]},{"cell_type":"markdown","metadata":{},"source":["# Utility functions"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["# Constants\n","# results_path = \"kaggle\"\n","# experiment_name = \"working\"\n","FULL_PATH = f'output'\n","fixed_noise = th.randn(64, NOISE_SIZE, 1, 1, device=device)\n","\n","# Create output folder if it doesn't exist yet\n","if not os.path.isdir('output'): \n","    os.mkdir('output')\n","\n","# Utility functions\n","def save_model_checkpoint(epoch: int) -> None:\n","    make_epoch_directories(epoch)\n","    checkpoint_path = f'{FULL_PATH}/{epoch}'\n","    th.save({\n","        'epoch': epoch,\n","        'generator_model_state_dict': generator.state_dict(),\n","        'discriminator_model_state_dict': critic.state_dict(),\n","        'generator_optimizer_state_dict': generator_optimizer.state_dict(),\n","        'discriminator_optimizer_state_dict': critic_optimizer.state_dict(),\n","    }, f'{checkpoint_path}/checkpoint.th')\n","\n","\n","def make_epoch_directories(epoch: int) -> None:\n","    epoch_path = f'{FULL_PATH}/{epoch}'\n","    if not os.path.isdir(epoch_path):\n","        os.mkdir(epoch_path)\n","\n","\n","def save_model_image(epoch: int) -> None:\n","    make_epoch_directories(epoch)\n","    image_path = f'{FULL_PATH}/{epoch}/images'\n","    if not os.path.isdir(image_path):\n","        os.mkdir(image_path)\n","    random_noise = th.randn(64, NOISE_SIZE, 1, 1, device=device)\n","    fixed_fakes = generator(fixed_noise).detach().cpu()\n","    random_fakes = generator(random_noise).detach().cpu()\n","    save_image_grid(fixed_fakes, f'{image_path}/fixed.png', 'Fixed Noise')\n","    save_image_grid(random_fakes, f'{image_path}/random.png', 'Random Noise')\n","\n","\n","def save_image_grid(images, path: str, title: str) -> None:\n","    plt.figure(figsize=(8,8))\n","    plt.axis('off')\n","    plt.title(title)\n","    plt.imshow(np.transpose(vutils.make_grid(images.to(device)[:64], padding=2, normalize=True).cpu(), (1, 2, 0)))\n","    plt.savefig(path)\n","    plt.close()"]},{"cell_type":"markdown","metadata":{},"source":["# Training loop\n","Main training loop. Note that we use the algorithm outlined in the WGAN paper. So in this case the Critic is updated more frequently (5x) and we use the Loss Function descrbied in the paper (and other resources online see: https://machinelearningmastery.com/how-to-implement-wasserstein-loss-for-generative-adversarial-networks/) \n","\n","From this blogpost:\n","    Critic Loss = [average critic score on real images] – [average critic score on fake images]\n","    Generator Loss = -[average critic score on fake images]\n"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["VERSION: 21\n","EPOCH:  0\n"]}],"source":["\n","# MAIN TRAINING LOOP\n","print(\"VERSION:\", VERSION)\n","for epoch in range(EPOCHS + 1):\n","    print('EPOCH: ', epoch)\n","\n","    for batch_idx, (real, _) in enumerate(dataloader):\n","        real = real.to(device)\n","        batch_size = real.size(0)\n","        \n","        # TRAIN DISCRIMINATOR (CRITIC) MORE. (5x according to paper)\n","        for _ in range(CRITIC_ITERATIONS):\n","            noise = th.randn(batch_size, NOISE_SIZE, 1, 1, device=device)\n","            fake = generator(noise)\n","            \n","            critic_fake = critic(fake).reshape(-1)\n","    \n","            critic_real = critic(real).reshape(-1)\n","            \n","            # extra '-' because originally we want to maximize, so we minimize the negative.\n","            # LAMDA_GP * gp is the addition for WGAN-GP\n","            loss_critic = -(th.mean(critic_real) - th.mean(critic_fake))\n","            \n","            critic.zero_grad()\n","            loss_critic.backward(retain_graph=True)\n","            critic_optimizer.step()\n","            \n","        \n","        # TRAIN GENERATOR \n","        output = critic(fake).reshape(-1)\n","        loss_generator = -th.mean(output)\n","        generator.zero_grad() \n","        loss_generator.backward()\n","        generator_optimizer.step()\n","\n","\n","    # SAVE MODEL AND IMAGES\n","    if epoch % SAVE_CHECKPOINT_EVERY == 0:\n","        print('-> Saving model checkpoint')\n","        save_model_checkpoint(epoch)\n","    \n","    if epoch % SAVE_IMAGE_EVERY == 0:\n","        print('-> Saving model images')\n","        save_model_image(epoch)"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"interpreter":{"hash":"0710d308d66b8004f73af2ec28aa1130c98ac659d02c9b147a320fe9d85a0088"},"kernelspec":{"display_name":"Python 3.10.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":4}
